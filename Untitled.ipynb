{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c2d79-571e-455e-b7a9-392dcecd181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from itertools import chain\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from progressbar import ETA, Bar, Percentage, ProgressBar\n",
    "import simpleaudio as sa\n",
    "# from model_Adp import *\n",
    "from model_Adp_custom import *\n",
    "import scipy.io as sio\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import pad\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import *\n",
    "import torchvision\n",
    "from collections import defaultdict\n",
    "from IPython.display import display\n",
    "import torchaudio\n",
    "from torchvision.transforms.functional import pad\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1fad0-434f-42c0-8aa5-1d1006d86c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda = torch.cuda.is_available()\n",
    "# print(cuda)\n",
    "\n",
    "ngpu = 2\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a5e967-7dd3-4a83-99e2-50e2e1a83b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read MNIST meta file and move folders to respective male and female folders\n",
    "# import json\n",
    "# import shutil\n",
    "  \n",
    "# # reading the data from the file\n",
    "# with open('data/AudioMNIST/audioMNIST_meta.txt') as f:\n",
    "#     data = f.read()\n",
    "    \n",
    "# data = json.loads(data)\n",
    "\n",
    "# for key, value in data.items():\n",
    "#     if value['gender'] == \"male\":\n",
    "#         for file in glob.glob(\"./data/AudioMNIST/\"+key+\"/*\"):\n",
    "#             shutil.move(file, \"./data/AudioMNIST/male/\"+Path(file).stem+\".wav\")\n",
    "#     elif value['gender'] == \"female\":\n",
    "#         for file in glob.glob(\"./data/AudioMNIST/\"+key+\"/*\"):\n",
    "#             shutil.move(file, \"./data/AudioMNIST/female/\"+Path(file).stem+\".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0661245-7e5f-4565-8b2f-95eb9371300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_test = \"data/wavfiles16kHz/TEST\"\n",
    "# path_train = \"data/wavfiles16kHz/TRAIN\"\n",
    "\n",
    "path_A = \"data/AudioMNIST/male\"\n",
    "path_B = \"data/AudioMNIST/female\"\n",
    "\n",
    "n = 1000\n",
    "\n",
    "files_A = glob.glob(path_A+\"/*.wav\")[:n]\n",
    "files_B = glob.glob(path_B+\"/*.wav\")[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc28ca-1319-4c5f-8ff3-eccdcb2c6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_np(data):\n",
    "    return data.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db70ae7-5dd9-496f-a069-df0d1de82d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def padding(array, xx, yy):\n",
    "#     \"\"\"\n",
    "#     :param array: numpy array\n",
    "#     :param xx: desired height\n",
    "#     :param yy: desirex width\n",
    "#     :return: padded array\n",
    "#     \"\"\"\n",
    "\n",
    "#     h = array.shape[0]\n",
    "#     w = array.shape[1]\n",
    "\n",
    "#     a = (xx - h) // 2\n",
    "#     aa = xx - a - h\n",
    "\n",
    "#     b = (yy - w) // 2\n",
    "#     bb = yy - b - w\n",
    "\n",
    "#     return np.pad(array, pad_width=((a, aa), (b, bb)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342fcc11-3e97-4e36-b87b-2c5e9c3455f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(files_A[1])\n",
    "\n",
    "class AudioNormalize(object):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "\n",
    "    \"Normalizes a single `AudioTensor`.\"\n",
    "    def encodes(self): return (self.x-self.x.mean()) / self.x.std()\n",
    "\n",
    "print(waveform.mean())\n",
    "print(waveform.var())\n",
    "\n",
    "def extract_logmel(y, sr, size=3):\n",
    "    \"\"\"\n",
    "    extract log mel spectrogram feature\n",
    "    :param y: the input signal (audio time series)\n",
    "    :param sr: sample rate of 'y'\n",
    "    :param size: the length (seconds) of random crop from original audio, default as 3 seconds\n",
    "    :return: log-mel spectrogram feature\n",
    "    \"\"\"\n",
    "    # normalization\n",
    "    y = y.astype(np.float32)\n",
    "    normalization_factor = 1 / np.max(np.abs(y))\n",
    "    y = y * normalization_factor\n",
    "\n",
    "    # extract log mel spectrogram\n",
    "    melspectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024, n_mels=128)\n",
    "    logmelspec = librosa.power_to_db(melspectrogram)\n",
    "\n",
    "    return logmelspec \n",
    "\n",
    "ps_db = extract_logmel(as_np(waveform).squeeze(), sample_rate)\n",
    "\n",
    "print(ps_db.mean())\n",
    "print(ps_db.var())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,10))\n",
    "plt.imshow(ps_db, origin=\"lower\", cmap=plt.get_cmap(\"magma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(array, xx, yy):\n",
    "    \"\"\"\n",
    "    :param array: numpy array\n",
    "    :param xx: desired height\n",
    "    :param yy: desirex width\n",
    "    :return: padded array\n",
    "    \"\"\"\n",
    "\n",
    "    h = array.shape[0]\n",
    "    w = array.shape[1]\n",
    "\n",
    "    a = (xx - h) // 2\n",
    "    aa = xx - a - h\n",
    "\n",
    "    b = (yy - w) // 2\n",
    "    bb = yy - b - w\n",
    "\n",
    "    return np.pad(array, pad_width=((a, aa), (b, bb)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8667d-77f2-4450-964c-cb6b81167082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample_rate, samples = wavfile.read(test_files[3])\n",
    "# # frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "\n",
    "# # y, sr = librosa.load(files_A[1])\n",
    "# ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "# ps_db= librosa.power_to_db(ps, ref=np.max)\n",
    "\n",
    "# # ps_db = padding(ps_db, 256, 256)\n",
    "\n",
    "# # librosa.display.specshow(ps_db, x_axis='s', y_axis='log')\n",
    "# fig, ax = plt.subplots(figsize=(5,10))\n",
    "# plt.imshow(ps_db, origin=\"lower\", cmap=plt.get_cmap(\"magma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818dc64-e768-4a86-aafd-b1c5ec796d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image to npy array\n",
    "spect_dir_A = \"./data/spectrograms/A/\" \n",
    "spect_dir_B = \"./data/spectrograms/B/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91aefeb-6a39-4121-9b60-b0f8270325a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_np(files, savepath):\n",
    "    for i, file in zip(tqdm(range(n)), files):\n",
    "        # y, sr = librosa.load(file)\n",
    "        # ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        # ps_db = librosa.power_to_db(ps, ref=np.max)\n",
    "        waveform, sample_rate = torchaudio.load(file)\n",
    "\n",
    "        waveform = AudioNormalize(waveform).encodes()\n",
    "        ps_db = extract_logmel(as_np(waveform).squeeze(), sample_rate)\n",
    "\n",
    "        np.save(savepath+Path(file).stem+\".npy\", ps_db)\n",
    "        \n",
    "        # display.clear_output(wait=True)\n",
    "        \n",
    "save_as_np(files_A, spect_dir_A)\n",
    "save_as_np(files_B, spect_dir_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58465f-3e12-426c-9a47-7799854443a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TIMITDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.img_path = glob.glob(self.img_dir+\"*.npy\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_path[idx]\n",
    "        image = np.load(img_path)\n",
    "        image = padding(image, 128, 128)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)   \n",
    "    \n",
    "        return image\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "    \n",
    "# dataset = torchvision.datasets.ImageFolder(spect_dir, transform)\n",
    "data_A = TIMITDataset(spect_dir_A, transform=transform)\n",
    "data_B = TIMITDataset(spect_dir_B, transform=transform)\n",
    "\n",
    "print(data_A.__len__())\n",
    "print(data_B.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363203e6-d7bb-4f69-b3f7-c6e3777ed5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 1\n",
    "\n",
    "data_A.__getitem__(img).mean()\n",
    "data_A.__getitem__(img).var()\n",
    "data_A.__getitem__(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d65298-0838-4d28-bd5b-e56b553be4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def image_grid(d, idxs):\n",
    "#     images = [d[idx][0] for idx in idxs]\n",
    "#     grid = torchvision.utils.make_grid(images)\n",
    "#     return grid.numpy().transpose(1, 2, 0) / 2 + 0.5\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(image_grid(dataset, range(48)))\n",
    "# plt.title('Speech signals')\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d8a61-937b-4f6e-b473-16370640d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = int(n/4)\n",
    "# print(size)\n",
    "\n",
    "# data_A, data_B, test_A, test_B = torch.utils.data.random_split(dataset, [size, size, size, size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a0c45-df79-4b4d-9697-ca0354af8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter(data_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9cef01-1274-474c-b10c-a6ba4105a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "data_A = torch.utils.data.DataLoader(data_A, \n",
    "                                     batch_size=batch_size, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=num_workers,\n",
    "                                     drop_last=True)\n",
    "\n",
    "data_B = torch.utils.data.DataLoader(data_B, \n",
    "                                     batch_size=batch_size, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=num_workers,\n",
    "                                     drop_last=True)\n",
    "\n",
    "# test_A = torch.utils.data.DataLoader(test_A, \n",
    "#                                      batch_size=batch_size, \n",
    "#                                      shuffle=True, \n",
    "#                                      num_workers=num_workers)\n",
    "\n",
    "# test_B = torch.utils.data.DataLoader(test_B, \n",
    "#                                      batch_size=batch_size, \n",
    "#                                      shuffle=True, \n",
    "#                                      num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7818f-6946-4c61-bd77-2c87427d5c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image.\n",
    "train_features = next(iter(data_A))\n",
    "print(train_features.shape)\n",
    "img = train_features[0].squeeze()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4319f-80e9-43ba-9e6d-65cce635327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tensor = next(iter(data_A))\n",
    "print(batch_tensor[0][0])\n",
    "grid_img = torchvision.utils.make_grid(batch_tensor, nrow=4, normalize=True)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Example speech')\n",
    "plt.axis('off')\n",
    "plt.imshow(grid_img.permute(1, 2, 0), origin=\"lower\", cmap=plt.get_cmap(\"magma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d9fda-993b-48c0-a9ba-b5934d0cd42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_style_A, data_style_B, test_style_A, test_style_B = np.array_split(glob.glob(spect_dir+\"*.npy\"), 4)\n",
    "# data_style_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d518f-b182-4117-97cc-7a92a1e8b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_spect_matrix(filenames):\n",
    "#     images = []\n",
    "#     for fn in filenames:\n",
    "#         if fn[-3:] == 'mat':\n",
    "#             image = scipy.io.loadmat(fn)\n",
    "#             # pdb.set_trace()\n",
    "#             image = image[fn[-12:-4]] #12 for val \\, 14 for train\n",
    "#             # make it 3x256x256\n",
    "#             image = image.transpose(2,0,1)\n",
    "#         elif fn[-3:] == 'npy':\n",
    "#             image = np.load(fn)\n",
    "#         if image is None:\n",
    "#             continue\n",
    "#         image = image.astype(np.float32)\n",
    "#         # Saved as (3, 256, 256)\n",
    "#         # image = image.transpose(2,0,1)\n",
    "#         # pdb.set_trace( )\n",
    "#         images.append( image )\n",
    "\n",
    "#     images = np.stack( images )\n",
    "#     return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc203c-0317-405e-99d4-5448c7d0bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_A = read_spect_matrix( test_style_A )\n",
    "# test_B = read_spect_matrix( test_style_B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c4471-eb61-4623-8a3f-86c8d53a417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_A_V = Variable( torch.FloatTensor( test_A ), requires_grad=True)\n",
    "# test_B_V = Variable( torch.FloatTensor( test_B ), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140d2b9-51e7-46cc-977c-8de2fd39a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = min( len(data_A), len(data_B) )\n",
    "\n",
    "print(n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb979c9-d9b4-42b8-b58e-7cfd3021b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_batches = ( data_size // batch_size )\n",
    "\n",
    "# n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c535b5a-db2c-41a8-a038-582ee5bca240",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_criterion = nn.L1Loss() #MSELoss()\n",
    "gan_criterion = nn.BCELoss()\n",
    "feat_criterion = nn.HingeEmbeddingLoss()\n",
    "stl_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b2ddf-3cc6-4148-8460-e304bf3d484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change to 3 inputs \n",
    "def get_gan_loss(dis_real, dis_fake1, dis_fake2, criterion, device):\n",
    "    labels_dis_real = Variable(torch.ones( [dis_real.size()[0], 1] ))\n",
    "    labels_dis_fake1 = Variable(torch.zeros([dis_fake1.size()[0], 1] ))\n",
    "    labels_dis_fake2 = Variable(torch.zeros([dis_fake2.size()[0], 1] ))\n",
    "    labels_gen1 = Variable(torch.ones([dis_fake1.size()[0], 1]))\n",
    "    labels_gen2 = Variable(torch.ones([dis_fake2.size()[0], 1]))\n",
    "\n",
    "    labels_dis_real = labels_dis_real.to(device)\n",
    "    labels_dis_fake1 = labels_dis_fake1.to(device)\n",
    "    labels_dis_fake2 = labels_dis_fake2.to(device)\n",
    "    labels_gen1 = labels_gen1.to(device)\n",
    "    labels_gen2 = labels_gen2.to(device)\n",
    "    \n",
    "    dis_real = torch.reshape(dis_real, (batch_size,1))\n",
    "    dis_fake1 = torch.reshape(dis_fake1, (batch_size,1))\n",
    "    dis_fake2 = torch.reshape(dis_fake2, (batch_size,1))\n",
    "    \n",
    "    dis_loss = criterion( dis_real, labels_dis_real ) * 0.4 + criterion( dis_fake1, labels_dis_fake1 ) * 0.3 + criterion( dis_fake2, labels_dis_fake2 ) * 0.3\n",
    "    gen_loss = criterion( dis_fake1, labels_gen1 ) * 0.5 + criterion( dis_fake2, labels_gen2 ) * 0.5\n",
    "\n",
    "    return dis_loss, gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b03d2-416c-4637-9df8-27cbe8c1c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fm_loss(real_feats, fake_feats, criterion, device):\n",
    "    losses = 0\n",
    "    for real_feat, fake_feat in zip(real_feats, fake_feats):\n",
    "        # pdb.set_trace()\n",
    "        l2 = (real_feat.mean(0) - fake_feat.mean(0)) * (real_feat.mean(0) - fake_feat.mean(0))\n",
    "        loss = criterion( l2, Variable( torch.ones( l2.size() ) ).to(device) )\n",
    "        losses += loss\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58d000-532f-4765-8f68-758e057ccf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use CrossEntropyLoss: target should be N\n",
    "def get_stl_loss(A_stl, A1_stl, A2_stl, B_stl, B1_stl, B2_stl, criterion, device):\n",
    "    # for nn.CrossEntropyLoss, the target is class index.\n",
    "    labels_A = Variable(torch.ones( A_stl.size()[0] )) # NLL/CE target N not Nx1\n",
    "    labels_A.data =  labels_A.data.type(torch.LongTensor)\n",
    "\n",
    "    labels_A1 = Variable(torch.ones( A1_stl.size()[0] )) # NLL/CE target N not Nx1\n",
    "    labels_A1.data =  labels_A1.data.type(torch.LongTensor)\n",
    "\n",
    "    labels_A2 = Variable(torch.ones( A2_stl.size()[0] )) # NLL/CE target N not Nx1\n",
    "    labels_A2.data =  labels_A2.data.type(torch.LongTensor)\n",
    " \n",
    "    labels_B = Variable(torch.zeros(B_stl.size()[0] ))\n",
    "    labels_B.data =  labels_B.data.type(torch.LongTensor)\n",
    "\n",
    "    labels_B1 = Variable(torch.zeros(B1_stl.size()[0] ))\n",
    "    labels_B1.data =  labels_B1.data.type(torch.LongTensor)\n",
    "\n",
    "    labels_B2 = Variable(torch.zeros(B2_stl.size()[0] ))\n",
    "    labels_B2.data =  labels_B2.data.type(torch.LongTensor)\n",
    "   \n",
    "    labels_A = labels_A.to(device)\n",
    "    labels_A1 = labels_A1.to(device)\n",
    "    labels_A2 = labels_A2.to(device)\n",
    "    labels_B = labels_B.to(device)\n",
    "    labels_B1 = labels_B1.to(device)\n",
    "    labels_B2 = labels_B2.to(device)\n",
    "\n",
    "    A_stl = np.squeeze(A_stl)\n",
    "    A1_stl = np.squeeze(A1_stl)\n",
    "    A2_stl = np.squeeze(A2_stl)\n",
    "    B_stl = np.squeeze(B_stl)\n",
    "    B1_stl = np.squeeze(B1_stl)\n",
    "    B2_stl = np.squeeze(B2_stl)\n",
    "\n",
    "    stl_loss_A = criterion( A_stl, labels_A ) * 0.2 + criterion( A1_stl, labels_A1 ) * 0.15 + criterion( A2_stl, labels_A2 ) * 0.15\n",
    "    stl_loss_B = criterion( B_stl, labels_B ) * 0.2 + criterion( B1_stl, labels_B1 ) * 0.15 + criterion( B2_stl, labels_B2 ) * 0.15\n",
    "    stl_loss = stl_loss_A + stl_loss_B\n",
    "\n",
    "    return stl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72938066-9850-48f7-b220-ca203b80c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_regu(input_v, batch_size, criterion=nn.MSELoss()):\n",
    "    losses = 0\n",
    "    for i in range(batch_size):\n",
    "        # pdb.set_trace()\n",
    "        input_temp = np.squeeze(input_v.data[i,:,:,:])\n",
    "        # no need to take mean among 3 channels since current input is 256x256 instead of 3x256x256\n",
    "        input_temp = input_temp.cpu().numpy()\n",
    "        input_delta = np.absolute(librosa.feature.delta(input_temp))\n",
    "        b = input_delta.shape[1]\n",
    "        delta_loss = criterion(Variable((torch.from_numpy(input_delta)).type(torch.DoubleTensor)), Variable((torch.zeros([128,b])).type(torch.DoubleTensor)))\n",
    "        # delta_loss = criterion((torch.from_numpy(input_delta)), Variable((torch.zeros([256,256]))))\n",
    "        losses += delta_loss\n",
    "\n",
    "    delta_losses = losses/batch_size\n",
    "\n",
    "    return delta_losses.type(torch.cuda.FloatTensor)  \n",
    "    # return delta_losses.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474210a-396d-4c89-9b73-6ced0be3794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_A = Generator(ngpu)\n",
    "generator_B = Generator(ngpu)\n",
    "discriminator_A = Discriminator(ngpu)\n",
    "discriminator_B = Discriminator(ngpu)\n",
    "discriminator_S = StyleDiscriminator(ngpu)\n",
    "\n",
    "generator_A = generator_A.to(device)\n",
    "generator_B = generator_B.to(device)\n",
    "discriminator_A = discriminator_A.to(device)\n",
    "discriminator_B = discriminator_B.to(device)\n",
    "discriminator_S = discriminator_S.to(device)\n",
    "    \n",
    "if ngpu > 1:\n",
    "    generator_A = nn.DataParallel(generator_A, device_ids = range(ngpu))\n",
    "    generator_B = nn.DataParallel(generator_B, device_ids = range(ngpu))\n",
    "    discriminator_A = nn.DataParallel(discriminator_A, device_ids = range(ngpu))\n",
    "    discriminator_B = nn.DataParallel(discriminator_B, device_ids = range(ngpu))\n",
    "    discriminator_S = nn.DataParallel(discriminator_S, device_ids = range(ngpu)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193d876-f59a-4668-a9fd-24e289954080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generator_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb39f2-4e78-446b-970e-4543e2c0b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params = chain(generator_A.parameters(), generator_B.parameters())\n",
    "dis_params = chain(discriminator_A.parameters(), discriminator_B.parameters())\n",
    "stl_params =  discriminator_S.parameters() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44970c7-979b-4a14-846a-5492c07f7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4794f-504c-45de-8da3-df48ceb11075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (A,B) in enumerate(zip(data_A,data_B)):\n",
    "#     A = Variable(A).to(device)\n",
    "    \n",
    "#     print(A.shape)\n",
    "    \n",
    "#     AB, AL_feats, LAB_feats = generator_B(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd086f-acd7-4b8a-a170-bb39c831316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optim_gen = optim.Adam( gen_params, lr=learning_rate, betas=(0.5,0.999), weight_decay=0.00001)\n",
    "optim_dis = optim.Adam( dis_params, lr=learning_rate, betas=(0.5,0.999), weight_decay=0.00001)\n",
    "optim_stl = optim.Adam( stl_params, lr=learning_rate, betas=(0.5,0.999), weight_decay=0.00001)\n",
    "\n",
    "iters = 0\n",
    "start = time.time()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f1e3a5-753d-486b-a576-1f3fd4414d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(iter(data_A)).size())\n",
    "print(next(iter(data_B)).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61105a24-94c1-4b51-8372-48d27f7d070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 50\n",
    "\n",
    "# Strong GAN loss for certain period at the beginning\n",
    "gan_curriculum = 1000\n",
    "# Set the lambda weight between GAN loss and Recon loss during curriculum period at the beginning. We used the 0.01 weight\n",
    "starting_rate = 0.01\n",
    "# Set the lambda weight between GAN loss and Recon loss after curriculum period. We used the 0.5 weight\n",
    "default_rate = 0.1\n",
    "# choose among gan/recongan/discogan/spec_gan. gan - standard GAN, recongan - GAN with reconstruction, discogan - DiscoGAN, spec_gan - My modified GAN model for speech\n",
    "model_arch = \"spec_gan\"\n",
    "# Print loss values every log_interval iterations\n",
    "log_interval = epoch_size\n",
    "# Save test results every image_save_interval iterations\n",
    "image_save_interval = 2000\n",
    "# Save models every model_save_interval iterations\n",
    "model_save_interval = 10000\n",
    "# Set the path for trained models\n",
    "model_path = \"./models/\"\n",
    "task_name = \"spectrogram\"\n",
    "\n",
    "model_path = os.path.join( model_path, task_name )\n",
    "model_path = os.path.join( model_path, model_arch )\n",
    "\n",
    "Path(model_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "result_path = './results'\n",
    "update_interval = 10\n",
    "\n",
    "log_gen_loss = np.array([])\n",
    "log_dis_loss = np.array([])\n",
    "log_stl_loss = np.array([])\n",
    "log_delta_A = np.array([])\n",
    "log_delta_B = np.array([])\n",
    "log_fm_loss_A = np.array([])\n",
    "log_fm_loss_B = np.array([])\n",
    "log_recon_loss_A = np.array([])\n",
    "log_recon_loss_B = np.array([])\n",
    "log_gen_loss_A = np.array([])\n",
    "log_gen_loss_B = np.array([])\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "\n",
    "for epoch in range(epoch_size):    \n",
    "    epoch_stats = defaultdict(lambda: 0)\n",
    "    widgets = ['epoch #%d|' % epoch, Percentage(), Bar(), ETA()]\n",
    "    pbar = ProgressBar(maxval=n_batches, widgets=widgets)\n",
    "    pbar.start()\n",
    "        \n",
    "    for i, (A,B) in enumerate(zip(data_A,data_B)):\n",
    "        pbar.update(i)\n",
    "\n",
    "        generator_A.zero_grad()\n",
    "        generator_B.zero_grad()\n",
    "        discriminator_A.zero_grad()\n",
    "        discriminator_B.zero_grad()\n",
    "        discriminator_S.zero_grad()\n",
    "           \n",
    "        A = Variable( torch.FloatTensor( A ) ).to(device)\n",
    "        B = Variable( torch.FloatTensor( B ) ).to(device)\n",
    "\n",
    "        # test_A_V = Variable( torch.FloatTensor( t_A ), requires_grad=True )\n",
    "        # test_B_V = Variable( torch.FloatTensor( t_B ), requires_grad=True )\n",
    "    \n",
    "        # A -> AB -> ABA\n",
    "        # A = A.unsqueeze(1)\n",
    "        AB, AL_feats, LAB_feats = generator_B(A)\n",
    "        ABA, ABL_feats, ABLA_feats = generator_A(AB)\n",
    "        # B -> BA -> BAB\n",
    "        # B = B.unsqueeze(1)\n",
    "        BA, BL_feats, LBA_feats = generator_A(B)\n",
    "        BAB, BAL_feats, BALB_feats = generator_B(BA)\n",
    "        \n",
    "        recon_loss_BA = recon_criterion( BA, B)\n",
    "        recon_loss_AB = recon_criterion( AB, A)\n",
    "        recon_loss_ABA = recon_criterion( ABA, A)\n",
    "        recon_loss_BAB = recon_criterion( BAB, B)\n",
    "        \n",
    "        recon_loss_A = 30 *recon_loss_AB + 70 * recon_loss_ABA\n",
    "        recon_loss_B = 30 *recon_loss_BA + 70 * recon_loss_BAB \n",
    "        \n",
    "        # Real/Fake GAN Loss (A)\n",
    "        A_dis = discriminator_A( A )\n",
    "        BA_dis = discriminator_A( BA )\n",
    "        ABA_dis = discriminator_A( ABA )\n",
    "        \n",
    "        # will be strange in one epoch\n",
    "        dis_loss_A, gen_loss_A = get_gan_loss( A_dis, BA_dis, ABA_dis, gan_criterion, device)\n",
    "                \n",
    "        fm_loss_A1 = get_fm_loss(AL_feats, ABLA_feats, feat_criterion, device)\n",
    "        fm_loss_A2 = get_fm_loss(LAB_feats, ABL_feats, feat_criterion, device)\n",
    "        fm_loss_A = fm_loss_A1 + fm_loss_A2\n",
    "        \n",
    "        # Real/Fake GAN Loss (B)\n",
    "        B_dis = discriminator_B( B )\n",
    "        AB_dis = discriminator_B( AB )\n",
    "        BAB_dis = discriminator_B( BAB )\n",
    "\n",
    "        dis_loss_B, gen_loss_B = get_gan_loss( B_dis, AB_dis, BAB_dis, gan_criterion, device)\n",
    "        fm_loss_B1 = get_fm_loss( BL_feats, BALB_feats, feat_criterion, device)\n",
    "        fm_loss_B2 = get_fm_loss( LBA_feats, BAL_feats, feat_criterion, device)\n",
    "        fm_loss_B = fm_loss_B1 + fm_loss_B2\n",
    "        \n",
    "        # Style Discriminator Loss\n",
    "        A_stl = discriminator_S(A)\n",
    "        B_stl = discriminator_S(B)\n",
    "        AB_stl = discriminator_S(AB) \n",
    "        BA_stl = discriminator_S(BA)\n",
    "        ABA_stl = discriminator_S(ABA) \t\t\n",
    "        BAB_stl = discriminator_S(BAB)\n",
    "        \n",
    "        stl_loss = get_stl_loss(A_stl, BA_stl, ABA_stl, B_stl, AB_stl, BAB_stl, stl_criterion, device)\n",
    "\n",
    "        # Delta regularizer\n",
    "        BA_delta = delta_regu(BA, batch_size)\n",
    "        AB_delta = delta_regu(AB, batch_size)\n",
    "        ABA_delta = delta_regu(ABA, batch_size)\n",
    "        BAB_delta = delta_regu(BAB, batch_size)\n",
    "\n",
    "        delta_A = BA_delta + ABA_delta\n",
    "        delta_B = AB_delta + BAB_delta\n",
    "        \n",
    "        # Total Loss\n",
    "        if iters < gan_curriculum:\n",
    "            rate = starting_rate\n",
    "        else:\n",
    "            rate = default_rate\n",
    "            \n",
    "        gen_loss_A_total = (gen_loss_A) * (1.-rate) + (recon_loss_A*0.6 + fm_loss_A*0.3 + delta_A*0.1)*rate\n",
    "        gen_loss_B_total = (gen_loss_B) * (1.-rate) + (recon_loss_B*0.6 + fm_loss_B*0.3 + delta_B*0.1)*rate\n",
    "        \n",
    "        if model_arch == 'discogan':\n",
    "            gen_loss = gen_loss_A_total + gen_loss_B_total\n",
    "            dis_loss = dis_loss_A + dis_loss_B\n",
    "        elif model_arch == 'spec_gan':\n",
    "            gen_loss = gen_loss_A_total + gen_loss_B_total\n",
    "            dis_loss = dis_loss_A + dis_loss_B + stl_loss\n",
    "        elif model_arch == 'recongan':\n",
    "            gen_loss = gen_loss_A_total\n",
    "            dis_loss = dis_loss_B\n",
    "        elif model_arch == 'gan':\n",
    "            gen_loss = (gen_loss_B*0.1 + fm_loss_B*0.9)\n",
    "            dis_loss = dis_loss_B\n",
    "            \n",
    "        if iters % update_interval == 0:\n",
    "            dis_loss.backward()\n",
    "            optim_dis.step()\n",
    "            optim_stl.step() \n",
    "        else:\n",
    "            gen_loss.backward()\n",
    "            optim_gen.step()\n",
    "            \n",
    "        if i % 50 == 0:\n",
    "        # if iters % log_interval == 0:\n",
    "            print(\"---------------------\")\n",
    "            print(\"GEN Loss:\", as_np(gen_loss_A.mean()), as_np(gen_loss_B.mean()))\n",
    "            print(\"Feature Matching Loss:\", as_np(fm_loss_A.mean()), as_np(fm_loss_B.mean()))\n",
    "            print(\"RECON Loss:\", as_np(recon_loss_A.mean()), as_np(recon_loss_B.mean()))\n",
    "            print(\"DIS Loss:\", as_np(dis_loss_A.mean()), as_np(dis_loss_B.mean()))\n",
    "            print(\"Style Loss:\", as_np(stl_loss.mean()))\n",
    "            print(\"Delta Loss:\", as_np(delta_A.mean()), as_np(delta_B.mean()))\n",
    "            print(\"Time\", (time.time()-start))\n",
    "            start = time.time()     \n",
    "                        \n",
    "            log_gen_loss = np.hstack([log_gen_loss, as_np(gen_loss.mean())])\n",
    "            log_dis_loss = np.hstack([log_dis_loss, as_np(dis_loss.mean())])\n",
    "            log_stl_loss = np.hstack([log_stl_loss, as_np(stl_loss.mean())])\n",
    "            log_delta_A = np.hstack([log_delta_A, as_np(delta_A.mean())])\n",
    "            log_delta_B = np.hstack([log_delta_B, as_np(delta_B.mean())])\n",
    "            log_fm_loss_A = np.hstack([log_fm_loss_A, as_np(fm_loss_A.mean())])\n",
    "            log_recon_loss_A = np.hstack([log_recon_loss_A, as_np(recon_loss_A.mean())])\n",
    "            log_fm_loss_B = np.hstack([log_fm_loss_B, as_np(fm_loss_B.mean())])\n",
    "            log_recon_loss_B = np.hstack([log_recon_loss_B, as_np(recon_loss_B.mean())])\n",
    "            log_gen_loss_A = np.hstack([log_gen_loss_A, as_np(gen_loss_A.mean())])\n",
    "            log_gen_loss_B = np.hstack([log_gen_loss_B, as_np(gen_loss_B.mean())])\n",
    "            \n",
    "            epoch_stats['log_gen_loss'] = log_gen_loss\n",
    "            \n",
    "#         if iters % image_save_interval == 0:\n",
    "#             # save test\n",
    "#             if test_A_V.shape[1] != 1:\n",
    "#                 test_A_V = test_A_V.unsqueeze(1)\n",
    "#                 test_B_V = test_B_V.unsqueeze(1)\n",
    "#             AB_test, testAL_feats, testLAB_feats = generator_B( test_A_V )\n",
    "#             BA_test, testBL_feats, testLBA_feats = generator_A( test_B_V )\n",
    "#             ABA_test, testABL_feats, testABLA_feats = generator_A( AB_test )\n",
    "#             BAB_test, testBAL_feats, testBALB_feats = generator_B( BA_test )\n",
    "\n",
    "#             n_testset = min( test_A_V.size()[0], test_B_V.size()[0] )\n",
    "\n",
    "#             subdir_path = os.path.join(result_path, str(iters / image_save_interval) )\n",
    "                        \n",
    "#             if Path(subdir_path).is_file():\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 Path(subdir_path).mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "#             for im_idx in range( n_testset ):\n",
    "#                 # pdb.set_trace()                    \n",
    "#                 A_val = test_A_V[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "#                 B_val = test_B_V[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "\n",
    "#                 BA_val = BA_test[im_idx].cpu().data.numpy().transpose(1,2,0) # * 255.\n",
    "#                 ABA_val = ABA_test[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "#                 AB_val = AB_test[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "#                 BAB_val = BAB_test[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "\n",
    "#                 filename_prefix = os.path.join (subdir_path, str(im_idx))\n",
    "\n",
    "#                 sio.savemat(filename_prefix +'.A_val_0.mat', {'A_val_0':A_val})\n",
    "#                 sio.savemat(filename_prefix +'.B_val_0.mat', {'B_val_0':B_val})\n",
    "#                 sio.savemat(filename_prefix +'.BA_val_0.mat', {'BA_val_0':BA_val})\n",
    "#                 sio.savemat(filename_prefix +'.AB_val_0.mat', {'AB_val_0':AB_val})\n",
    "#                 sio.savemat(filename_prefix +'.ABA_val_0.mat', {'ABA_val_0':ABA_val})\n",
    "#                 sio.savemat(filename_prefix +'.BAB_val_0.mat', {'BAB_val_0':BAB_val})\n",
    "                \n",
    "#             # save train\n",
    "\n",
    "#             n_trainset = batch_size\n",
    "\n",
    "#             for im_idx in range( n_trainset ):\n",
    "\n",
    "#                 A_train = A[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "#                 B_train = B[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "\n",
    "#                 BA_train = BA[im_idx].cpu().data.numpy().transpose(1,2,0) # * 255.\n",
    "#                 ABA_train = ABA[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "#                 AB_train = AB[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "#                 BAB_train = BAB[im_idx].cpu().data.numpy().transpose(1,2,0)# * 255.\n",
    "\n",
    "#                 filename_prefix = os.path.join (subdir_path, str(im_idx))\n",
    "                \n",
    "#                 sio.savemat(filename_prefix +'.A_train_0.mat', {'A_train_0':A_train})\n",
    "#                 sio.savemat(filename_prefix +'.B_train_0.mat', {'B_train_0':B_train})\n",
    "#                 sio.savemat(filename_prefix +'.BA_train_0.mat', {'BA_train_0':BA_train})\n",
    "#                 sio.savemat(filename_prefix +'.AB_train_0.mat', {'AB_train_0':AB_train})\n",
    "#                 sio.savemat(filename_prefix +'.ABA_train_0.mat', {'ABA_train_0':ABA_train})\n",
    "#                 sio.savemat(filename_prefix +'.BAB_train_0.mat', {'BAB_train_0':BAB_train})\n",
    "                \n",
    "        if iters % model_save_interval == 0:\n",
    "            torch.save( generator_A, os.path.join(model_path, 'model_gen_A-' + str( iters / model_save_interval )))\n",
    "            torch.save( generator_B, os.path.join(model_path, 'model_gen_B-' + str( iters / model_save_interval )))\n",
    "            torch.save( discriminator_A, os.path.join(model_path, 'model_dis_A-' + str( iters / model_save_interval )))\n",
    "            torch.save( discriminator_B, os.path.join(model_path, 'model_dis_B-' + str( iters / model_save_interval )))\n",
    "\n",
    "        iters += 1\n",
    "        \n",
    "        if epoch % 5 == 0 and iters % 10 == 0:\n",
    "            print('Epoch: '+str(epoch))\n",
    "            for k, v in epoch_stats.items():\n",
    "                print(' %s=%6.4f' % (k, v[-1] / iters), end='')\n",
    "\n",
    "            images_for_plot = {\n",
    "                'real_a': A, 'fake_ab': AB, 'cycle_aba': ABA,\n",
    "                'real_b': B, 'fake_ba': BA, 'cycle_bab': BAB,\n",
    "            }\n",
    "\n",
    "            for k in range(3):\n",
    "                for i, (im_title, im) in enumerate(images_for_plot.items()):\n",
    "                    plt.subplot(3, 6, k * 6 + i + 1)\n",
    "                    plt.imshow(im[k].detach().cpu().numpy().transpose(1, 2, 0) / 2 + 0.5)\n",
    "                    if k == 0:\n",
    "                        plt.title(im_title)\n",
    "                    plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "            plt.savefig( os.path.join(\"results/images/\", 'model-' + str( epoch ) + \".jpg\"))\n",
    "        \n",
    "sio.savemat(result_path +'/log_gen_loss.mat', {'log_gen_loss':log_gen_loss})\n",
    "sio.savemat(result_path +'/log_dis_loss.mat', {'log_dis_loss':log_dis_loss})\n",
    "sio.savemat(result_path +'/log_stl_loss.mat', {'log_stl_loss':log_stl_loss})\n",
    "sio.savemat(result_path +'/log_delta_A.mat', {'log_delta_A':log_delta_A})\n",
    "sio.savemat(result_path +'/log_delta_B.mat', {'log_delta_B':log_delta_B})\n",
    "sio.savemat(result_path +'/log_gen_loss_A.mat', {'log_gen_loss_A':log_gen_loss_A})\n",
    "sio.savemat(result_path +'/log_gen_loss_B.mat', {'log_gen_loss_B':log_gen_loss_B})\n",
    "sio.savemat(result_path +'/log_fm_loss_A.mat', {'log_fm_loss_A':log_fm_loss_A}) \n",
    "sio.savemat(result_path +'/log_fm_loss_B.mat', {'log_fm_loss_B':log_fm_loss_B})\n",
    "sio.savemat(result_path +'/log_recon_loss_A.mat', {'log_recon_loss_A':log_recon_loss_A}) \n",
    "sio.savemat(result_path +'/log_recon_loss_B.mat', {'log_recon_loss_B':log_recon_loss_B})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41217646-c78d-430e-bb77-3c71c5e91bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator, Discriminator and StyleDiscriminator Loss During Training\")\n",
    "plt.plot(log_gen_loss,label=\"G\")\n",
    "plt.plot(log_dis_loss,label=\"D\")\n",
    "plt.plot(log_stl_loss,label=\"G\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59a9ee-aaee-498a-bb7a-aa00f8fe9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_dis_loss)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1285c65d82dd15aa4dddc123b9e1fe531fbf318985019567a2c917f33b70a05d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
